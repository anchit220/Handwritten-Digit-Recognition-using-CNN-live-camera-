# -*- coding: utf-8 -*-
"""Handwritten Digit Recognition using CNN(live camera).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zqbdtBU-HeRakr3-BI8xuDwWEN7yB5tH
"""

# =====================================================
# LIVE MULTI-DIGIT RECOGNITION NOTEBOOK (COLAB)
# =====================================================

# Step 1️⃣: Install & Import Libraries
!pip install tensorflow opencv-python matplotlib

import tensorflow as tf
from tensorflow.keras.datasets import mnist
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense
import matplotlib.pyplot as plt
import numpy as np
import cv2
from IPython.display import display, Javascript
from google.colab.output import eval_js
from base64 import b64decode

# -------------------------------
# Step 2️⃣: Build & Train CNN
# -------------------------------
(x_train, y_train), (x_test, y_test) = mnist.load_data()
x_train = x_train / 255.0
x_test = x_test / 255.0
x_train = x_train.reshape(-1,28,28,1)
x_test = x_test.reshape(-1,28,28,1)

model = Sequential([
    Conv2D(32,(3,3),activation='relu', input_shape=(28,28,1)),
    MaxPooling2D((2,2)),
    Conv2D(64,(3,3),activation='relu'),
    MaxPooling2D((2,2)),
    Flatten(),
    Dense(128,activation='relu'),
    Dense(10,activation='softmax')
])

model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
model.fit(x_train, y_train, epochs=3, validation_data=(x_test, y_test))

# -------------------------------
# Step 3️⃣: Webcam Capture Function
# -------------------------------
def take_photo(filename='photo.jpg', quality=0.8):
    js = Javascript('''
    async function takePhoto(quality) {
      const div = document.createElement('div');
      const video = document.createElement('video');
      video.style.display = 'block';
      const capture = document.createElement('button');
      capture.textContent = 'Capture';
      div.appendChild(video);
      div.appendChild(capture);
      document.body.appendChild(div);

      const stream = await navigator.mediaDevices.getUserMedia({video: true});
      video.srcObject = stream;
      await video.play();

      await new Promise((resolve) => capture.onclick = resolve);

      const canvas = document.createElement('canvas');
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
      canvas.getContext('2d').drawImage(video, 0, 0);
      stream.getTracks().forEach(track => track.stop());
      div.remove();
      return canvas.toDataURL('image/jpeg', quality);
    }
    ''')
    display(js)
    data = eval_js('takePhoto({})'.format(quality))
    binary = b64decode(data.split(',')[1])
    with open(filename, 'wb') as f:
        f.write(binary)
    print(f"✅ Saved photo to {filename}")
    return filename

# -------------------------------
# Step 4️⃣: Multi-Digit Detection & Prediction
# -------------------------------
def detect_and_predict_digits(image_path, model):
    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)

    # Preprocess
    blur = cv2.GaussianBlur(img, (5,5), 0)
    thresh = cv2.adaptiveThreshold(
        blur, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
        cv2.THRESH_BINARY_INV, 11, 2
    )

    # Morphological closing to remove noise
    kernel = np.ones((2,2), np.uint8)
    thresh = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)

    # Find contours
    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    # Filter contours by size and aspect ratio
    filtered_contours = []
    for c in contours:
        x, y, w, h = cv2.boundingRect(c)
        if w*h < 300:       # too small
            continue
        if h < 15 or w < 5: # too narrow
            continue
        if h/w > 5 or w/h > 5: # extreme aspect ratio
            continue
        filtered_contours.append(c)

    # Sort left-to-right
    filtered_contours = sorted(filtered_contours, key=lambda c: cv2.boundingRect(c)[0])

    predicted_digits = []

    for c in filtered_contours:
        x, y, w, h = cv2.boundingRect(c)
        digit = thresh[y:y+h, x:x+w]
        digit = cv2.resize(digit, (20,20))
        padded = np.pad(digit, ((4,4),(4,4)), mode='constant', constant_values=0)
        padded = padded / 255.0
        padded = padded.reshape(1,28,28,1)

        pred = model.predict(padded, verbose=0)
        digit_label = np.argmax(pred)
        predicted_digits.append(str(digit_label))

        # Draw rectangle and label
        cv2.rectangle(img, (x,y), (x+w,y+h), (0,0,0), 2)
        cv2.putText(img, str(digit_label), (x, y-10),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,0,0), 2)

    # Display results
    if predicted_digits:
        print("✅ Predicted Number:", "".join(predicted_digits))
    else:
        print("❌ No digits detected. Try a clearer image.")

    plt.figure(figsize=(10,6))
    plt.imshow(img, cmap='gray')
    plt.axis('off')
    plt.title(f"Predicted Number: {''.join(predicted_digits)}")
    plt.show()

# -------------------------------
# Step 5️⃣: Capture & Predict
# -------------------------------
photo_path = take_photo()
detect_and_predict_digits(photo_path, model)